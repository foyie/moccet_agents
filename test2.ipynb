{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Initialize the embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Initialize the Gemini model\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2,0-flash\", temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain_anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y4/0lcmny8s1696ft7y4dphy7kr0000gn/T/ipykernel_20350/3301547011.py:3: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"llama3\")  # You can specify llama3, llama3:8b, llama2, etc.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama3\")  # You can specify llama3, llama3:8b, llama2, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "llm = ChatAnthropic(model=\"claude-3-sonnet-20240229\")  # Example model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not api_key:\n",
    "    raise ValueError(\"Anthropic API key not found. Check your .env file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",  # Full name required\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a business consultant. Analyze the provided documents and generate 3 actionable, section-referenced suggestions to improve the business model. Focus on revenue, operational efficiency, and customer satisfaction.\"),\n",
    "    (\"user\", \"{context}\\n\\n{question}\")\n",
    "])\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Load and split the PDF document\n",
    "def load_and_split_pdf(file_path):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    documents = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    return chunks\n",
    "\n",
    "# Process JSON dataset into Document chunks\n",
    "def process_json_dataset(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    documents = []\n",
    "    for entry in data:\n",
    "        documents.append(Document(page_content=f\"Brief: {entry['brief']}\\nSuggestions: {entry['suggestions']}\"))\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    return chunks\n",
    "\n",
    "# Build FAISS vectorstore\n",
    "def build_vectorstore(documents):\n",
    "    return FAISS.from_documents(documents, embedding_model)\n",
    "\n",
    "# Combined retrieval from both sources\n",
    "def retrieve_combined_context(pdf_vectorstore, json_vectorstore, query, k=2):\n",
    "    pdf_docs = pdf_vectorstore.similarity_search(query, k=k)\n",
    "    json_docs = json_vectorstore.similarity_search(query, k=k)\n",
    "\n",
    "    combined_context = \"\\n\\n\".join([doc.page_content for doc in pdf_docs + json_docs])\n",
    "    return combined_context\n",
    "\n",
    "# Business agent pipeline\n",
    "def business_agent_pipeline(client_pdf_path, client_query, json_dataset_path):\n",
    "    # Process client PDF\n",
    "    pdf_chunks = load_and_split_pdf(client_pdf_path)\n",
    "    pdf_vectorstore = build_vectorstore(pdf_chunks)\n",
    "\n",
    "    # Process JSON dataset\n",
    "    json_chunks = process_json_dataset(json_dataset_path)\n",
    "    json_vectorstore = build_vectorstore(json_chunks)\n",
    "\n",
    "    # Retrieve context\n",
    "    context = retrieve_combined_context(pdf_vectorstore, json_vectorstore, client_query, k=2)\n",
    "\n",
    "    # Run the LLM chain\n",
    "    response = chain.invoke({\"context\": context, \"question\": client_query})\n",
    "    return response[\"text\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ChatGoogleGenerativeAIError",
     "evalue": "Invalid argument provided to Gemini: 400 * GenerateContentRequest.model: unexpected model name format\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgument\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/agents_streamlit/.venv/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:192\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/agents_streamlit/.venv/lib/python3.13/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:868\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    867\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m868\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/agents_streamlit/.venv/lib/python3.13/site-packages/google/api_core/gapic_v1/method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/agents_streamlit/.venv/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/agents_streamlit/.venv/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:156\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    155\u001b[39m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     next_sleep = \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43msleep_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/agents_streamlit/.venv/lib/python3.13/site-packages/google/api_core/retry/retry_base.py:214\u001b[39m, in \u001b[36m_retry_error_helper\u001b[39m\u001b[34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[39m\n\u001b[32m    209\u001b[39m     final_exc, source_exc = exc_factory_fn(\n\u001b[32m    210\u001b[39m         error_list,\n\u001b[32m    211\u001b[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001b[32m    212\u001b[39m         original_timeout,\n\u001b[32m    213\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource_exc\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/agents_streamlit/.venv/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/agents_streamlit/.venv/lib/python3.13/site-packages/google/api_core/timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/agents_streamlit/.venv/lib/python3.13/site-packages/google/api_core/grpc_helpers.py:78\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mInvalidArgument\u001b[39m: 400 * GenerateContentRequest.model: unexpected model name format\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mChatGoogleGenerativeAIError\u001b[39m               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m json_dataset_path = \u001b[33m\"\u001b[39m\u001b[33m/Users/chandrimadas/Documents/agents_streamlit/business_agent_dataset_detailed.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m client_query = \u001b[33m\"\u001b[39m\u001b[33mSuggest a way to enhance patient satisfaction and retention in a healthcare mobile app, considering secure data handling and remote access features.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m suggestions = \u001b[43mbusiness_agent_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_pdf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_dataset_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müîç Business Agent Suggestions:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(suggestions)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mbusiness_agent_pipeline\u001b[39m\u001b[34m(client_pdf_path, client_query, json_dataset_path)\u001b[39m\n\u001b[32m     53\u001b[39m context = retrieve_combined_context(pdf_vectorstore, json_vectorstore, client_query, k=\u001b[32m2\u001b[39m)\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Run the LLM chain\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m response = \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_query\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/agents_streamlit/.venv/lib/python3.13/site-packages/langchain/chains/base.py:167\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    166\u001b[39m     run_manager.on_chain_error(e)\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    168\u001b[39m run_manager.on_chain_end(outputs)\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/agents_streamlit/.venv/lib/python3.13/site-packages/langchain/chains/base.py:157\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    155\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    156\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    159\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    160\u001b[39m     )\n\u001b[32m    162\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    163\u001b[39m         inputs, outputs, return_only_outputs\n\u001b[32m    164\u001b[39m     )\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/agents_streamlit/.venv/lib/python3.13/site-packages/langchain/chains/llm.py:127\u001b[39m, in \u001b[36mLLMChain._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call\u001b[39m(\n\u001b[32m    123\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    124\u001b[39m     inputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[32m    125\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    126\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.create_outputs(response)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/agents_streamlit/.venv/lib/python3.13/site-packages/langchain/chains/llm.py:139\u001b[39m, in \u001b[36mLLMChain.generate\u001b[39m\u001b[34m(self, input_list, run_manager)\u001b[39m\n\u001b[32m    137\u001b[39m callbacks = run_manager.get_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.llm, BaseLanguageModel):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    146\u001b[39m     results = \u001b[38;5;28mself\u001b[39m.llm.bind(stop=stop, **\u001b[38;5;28mself\u001b[39m.llm_kwargs).batch(\n\u001b[32m    147\u001b[39m         cast(\u001b[38;5;28mlist\u001b[39m, prompts), {\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m: callbacks}\n\u001b[32m    148\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/agents_streamlit/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:957\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    948\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    950\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    954\u001b[39m     **kwargs: Any,\n\u001b[32m    955\u001b[39m ) -> LLMResult:\n\u001b[32m    956\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/agents_streamlit/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:776\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    775\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    782\u001b[39m         )\n\u001b[32m    783\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    784\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/agents_streamlit/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1022\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1020\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1026\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/agents_streamlit/.venv/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:1342\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   1316\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1318\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1329\u001b[39m     **kwargs: Any,\n\u001b[32m   1330\u001b[39m ) -> ChatResult:\n\u001b[32m   1331\u001b[39m     request = \u001b[38;5;28mself\u001b[39m._prepare_request(\n\u001b[32m   1332\u001b[39m         messages,\n\u001b[32m   1333\u001b[39m         stop=stop,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1340\u001b[39m         tool_choice=tool_choice,\n\u001b[32m   1341\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1342\u001b[39m     response: GenerateContentResponse = \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1344\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1346\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1347\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1348\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/agents_streamlit/.venv/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:210\u001b[39m, in \u001b[36m_chat_with_retry\u001b[39m\u001b[34m(generation_method, **kwargs)\u001b[39m\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    208\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/agents_streamlit/.venv/lib/python3.13/site-packages/tenacity/__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/agents_streamlit/.venv/lib/python3.13/site-packages/tenacity/__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/agents_streamlit/.venv/lib/python3.13/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/agents_streamlit/.venv/lib/python3.13/site-packages/tenacity/__init__.py:400\u001b[39m, in \u001b[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[33m\"\u001b[39m\u001b[33mRetryCallState\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.iter_state.is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.retry_run_result):\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m         \u001b[38;5;28mself\u001b[39m._add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    401\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.after \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/agents_streamlit/.venv/lib/python3.13/site-packages/tenacity/__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/agents_streamlit/.venv/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:204\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    201\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m google.api_core.exceptions.InvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[32m    205\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    206\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[31mChatGoogleGenerativeAIError\u001b[39m: Invalid argument provided to Gemini: 400 * GenerateContentRequest.model: unexpected model name format\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    client_pdf_path = \"/Users/chandrimadas/Documents/agents_streamlit/sample_brief.pdf\"\n",
    "    json_dataset_path = \"/Users/chandrimadas/Documents/agents_streamlit/business_agent_dataset_detailed.json\"\n",
    "    client_query = \"Suggest a way to enhance patient satisfaction and retention in a healthcare mobile app, considering secure data handling and remote access features.\"\n",
    "\n",
    "    suggestions = business_agent_pipeline(client_pdf_path, client_query, json_dataset_path)\n",
    "    print(\"\\nüîç Business Agent Suggestions:\\n\")\n",
    "    print(suggestions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Health QA Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting beautifulsoup4 (from bs4)\n",
      "  Using cached beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->bs4)\n",
      "  Using cached soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./.venv/lib/python3.13/site-packages (from beautifulsoup4->bs4) (4.14.0)\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Using cached beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Using cached soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/3\u001b[0m [bs4]\n",
      "\u001b[1A\u001b[2KSuccessfully installed beautifulsoup4-4.13.4 bs4-0.0.2 soupsieve-2.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "urls = [\n",
    "    \"https://www.hhs.gov/hipaa/for-professionals/privacy/index.html\",\n",
    "    \"https://www.fda.gov/regulatory-information/search-fda-guidance-documents/mobile-medical-applications\",\n",
    "    \"https://www.hhs.gov/ash/patient-safety/index.html\"\n",
    "]\n",
    "\n",
    "# Load web pages directly\n",
    "loaders = [WebBaseLoader(url) for url in urls]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "qa_vectordb = FAISS.from_documents(chunks, embedding=embedding_model)\n",
    "\n",
    "# Save the vector store\n",
    "qa_vectordb.save_local(\"./health_qa_faiss_db\")\n",
    "# qa_vectordb = Chroma.from_documents(chunks, embedding=embedding_model, persist_directory=\"./health_qa_chroma_db\")\n",
    "\n",
    "qa_retriever = qa_vectordb.as_retriever(search_kwargs={\"k\": 5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a healthcare compliance officer and technical specification preparer. Your task is to validate business suggestions for compliance with HIPAA, FDA, and HHS regulations and refine them into technically actionable specifications.\\n\\n\"\n",
    "     \n",
    "     \"‚úÖ Instructions:\\n\"\n",
    "     \"- For each suggestion:\\n\"\n",
    "     \"  * If fully compliant, refine it into a detailed technical specification.\\n\"\n",
    "     \"  * If not compliant, modify it to comply.\\n\"\n",
    "     \"  * Exclude suggestions that cannot be made compliant.\\n\\n\"\n",
    "     \n",
    "     \"‚úÖ Output Format:\\n\"\n",
    "     \"- Provide a numbered list of refined, technically actionable suggestions.\\n\"\n",
    "     \"- Each suggestion must:\\n\"\n",
    "     \"    ‚Ä¢ Include specific technologies, frameworks, or implementation methods.\\n\"\n",
    "     \"    ‚Ä¢ Clearly describe how to ensure regulatory compliance (e.g., encryption standard, API security protocol).\\n\"\n",
    "    #  \"    ‚Ä¢ Include regulatory tags at the end like [HIPAA], [FDA], [HHS].\\n\"\n",
    "     \"    ‚Ä¢ Be written clearly enough for a technical team to immediately start system design or development.\\n\"\n",
    "     \"- Do not include introductions or explanations. Only output the refined suggestions.\\n\"\n",
    "    ),\n",
    "    (\"user\", \"{context}\\n\\nSuggestions to validate:\\n{suggestions}\")\n",
    "])\n",
    "\n",
    "\n",
    "qa_chain = LLMChain(llm=llm, prompt=qa_prompt)\n",
    "\n",
    "def run_healthcare_qa(suggestions, retriever):\n",
    "    query = \"Does this comply with HIPAA, FDA, and HHS guidelines?\"\n",
    "    relevant_docs = retriever.get_relevant_documents(query)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "\n",
    "    qa_response = qa_chain.invoke({\"context\": context, \"suggestions\": suggestions})\n",
    "    return qa_response[\"text\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "def load_healthcare_vectorstore():\n",
    "    \n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    \n",
    "    # Load the FAISS vector store from the saved directory\n",
    "    qa_vectordb = FAISS.load_local(\n",
    "        \"/Users/chandrimadas/Documents/agents_streamlit/vectorstores/healthcare_qa_faiss_db\", \n",
    "        embedding_model,\n",
    "        allow_dangerous_deserialization=True  # Add this if using newer versions\n",
    "    )\n",
    "    \n",
    "    return qa_vectordb.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_retriever = load_healthcare_vectorstore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ QA Agent Feedback:\n",
      "\n",
      "1. **Enhanced Revenue Streams through Value-Added Services:**\n",
      "\n",
      "* **Technical Specification:** Develop a tiered subscription model for the mobile application.  The premium tier will include:\n",
      "    * **Personalized Health Coaching:** Integrate with a third-party HIPAA-compliant health coaching platform via a secure API (using OAuth 2.0 for authorization).  Implement role-based access control (RBAC) to restrict access to patient data based on clinician and coach roles.  All communications will be encrypted using TLS 1.3 or higher.\n",
      "    * **Advanced Analytics and Reporting:** Utilize a HIPAA-compliant data analytics platform to generate personalized reports for patients and clinicians.  Data aggregation and analysis will be performed on de-identified data whenever possible.  Reports will be accessible via secure, password-protected user accounts with multi-factor authentication (MFA).  Data encryption at rest and in transit will be implemented using AES-256.\n",
      "    * **Wearable Device Integration:** Integrate with popular fitness trackers and smartwatches using FHIR (Fast Healthcare Interoperability Resources) standard APIs.  Data will be encrypted in transit and at rest.  Implement data validation and error handling to ensure data integrity.  Obtain explicit patient consent for data integration.\n",
      "    * **Educational Resources:** Develop a secure, HIPAA-compliant content management system (CMS) to host educational materials.  Access will be controlled through user authentication and authorization.  Content will be regularly reviewed and updated to ensure accuracy and compliance.\n",
      "\n",
      "2. **Improved Operational Efficiency through Automation and Integration:**\n",
      "\n",
      "* **Technical Specification:** Implement the following automated systems:\n",
      "    * **Appointment Scheduling:** Develop a HIPAA-compliant appointment scheduling module within the app using a scheduling API.  Integrate with calendar applications (e.g., Google Calendar, Outlook Calendar) via secure APIs.  Implement automated appointment reminders via SMS and email.  All appointment data will be encrypted using AES-256.\n",
      "    * **Automated Billing and Payment Processing:** Integrate with a HIPAA-compliant payment gateway (e.g., Stripe, Square) using their secure APIs.  Implement PCI DSS compliance for secure payment processing.  All transaction data will be encrypted using TLS 1.3 or higher.\n",
      "    * **Enhanced EHR Integration:** Utilize FHIR APIs to enable seamless data exchange between the app and existing EHR systems.  Implement robust error handling and data validation to ensure data integrity.  All data exchanged will be encrypted using TLS 1.3 or higher.  Implement audit trails to track all data access and modifications.\n",
      "\n",
      "3. **Boosted Customer Satisfaction and Retention through Personalized Experiences and Support:**\n",
      "\n",
      "* **Technical Specification:** Implement the following features:\n",
      "    * **Proactive Customer Support:** Develop an in-app help center with FAQs and tutorials.  Integrate with a HIPAA-compliant live chat platform for real-time support.  All support interactions will be logged and securely stored.\n",
      "    * **Personalized Onboarding and Training:** Develop interactive onboarding tutorials within the app.  Utilize personalized email sequences to guide users through key features.  Implement A/B testing to optimize onboarding effectiveness.\n",
      "    * **Regular Feedback Collection:** Implement in-app surveys and feedback forms.  Utilize a HIPAA-compliant feedback management system to collect, analyze, and act on feedback.  All feedback data will be anonymized whenever possible.  Implement a process for addressing and resolving customer issues promptly.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "qa_result = run_healthcare_qa(suggestions, qa_retriever)\n",
    "\n",
    "print(\"\\n‚úÖ QA Agent Feedback:\\n\")\n",
    "print(qa_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edu QA Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# URLs for Education Compliance\n",
    "edu_urls = [\n",
    "    \"https://studentprivacy.ed.gov/\",\n",
    "    \"https://www.ftc.gov/business-guidance/privacy-security/childrens-privacy\",\n",
    "    \"https://www.ada.gov/resources/overview/\"\n",
    "]\n",
    "\n",
    "# Load web pages\n",
    "edu_loaders = [WebBaseLoader(url) for url in edu_urls]\n",
    "edu_docs = []\n",
    "for loader in edu_loaders:\n",
    "    edu_docs.extend(loader.load())\n",
    "\n",
    "# Split documents\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)\n",
    "edu_chunks = splitter.split_documents(edu_docs)\n",
    "\n",
    "# Initialize embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Build Education Vector DB\n",
    "edu_qa_vectordb = Chroma.from_documents(edu_chunks, embedding=embedding_model, persist_directory=\"./edu_qa_chroma_db\")\n",
    "\n",
    "# Build Retriever\n",
    "edu_qa_retriever = edu_qa_vectordb.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# Education QA Prompt\n",
    "edu_qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are an education compliance officer and technical specification preparer. Validate business suggestions for FERPA, COPPA, and ADA compliance, and refine them into technically actionable specifications.\\n\\n\"\n",
    "     \"‚úÖ Instructions:\\n\"\n",
    "     \"- For each suggestion:\\n\"\n",
    "     \"  * If fully compliant, refine it into a detailed technical specification.\\n\"\n",
    "     \"  * If not compliant, modify it to comply.\\n\"\n",
    "     \"  * Exclude suggestions that cannot be made compliant.\\n\\n\"\n",
    "     \"‚úÖ Output Format:\\n\"\n",
    "     \"- Provide a numbered list of refined, technically actionable suggestions.\\n\"\n",
    "     \"- Each must:\\n\"\n",
    "     \"    ‚Ä¢ Include technologies, frameworks, and implementation methods.\\n\"\n",
    "     \"    ‚Ä¢ Clearly describe how to ensure FERPA, COPPA, and ADA compliance.\\n\"\n",
    "     \"- Do not include introductions or explanations. Only output the refined suggestions.\\n\"\n",
    "    ),\n",
    "    (\"user\", \"{context}\\n\\nSuggestions to validate:\\n{suggestions}\")\n",
    "])\n",
    "\n",
    "edu_qa_chain = LLMChain(llm=llm, prompt=edu_qa_prompt)\n",
    "\n",
    "def run_education_qa(suggestions, retriever):\n",
    "    query = \"Does this comply with FERPA, COPPA, and ADA regulations?\"\n",
    "    relevant_docs = retriever.get_relevant_documents(query)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "\n",
    "    edu_response = edu_qa_chain.invoke({\"context\": context, \"suggestions\": suggestions})\n",
    "    return edu_response[\"text\"].strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General qa agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# URLs for General Compliance\n",
    "general_urls = [\n",
    "    \"https://gdpr-info.eu/\",\n",
    "    \"https://oag.ca.gov/privacy/ccpa\",\n",
    "    \"https://www.ftc.gov/business-guidance/privacy-security\"\n",
    "]\n",
    "\n",
    "# Load web pages\n",
    "general_loaders = [WebBaseLoader(url) for url in general_urls]\n",
    "general_docs = []\n",
    "for loader in general_loaders:\n",
    "    general_docs.extend(loader.load())\n",
    "\n",
    "# Split documents\n",
    "general_chunks = splitter.split_documents(general_docs)\n",
    "\n",
    "# Build General Vector DB\n",
    "general_qa_vectordb = Chroma.from_documents(general_chunks, embedding=embedding_model, persist_directory=\"./general_qa_chroma_db\")\n",
    "\n",
    "# Build Retriever\n",
    "general_qa_retriever = general_qa_vectordb.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# General QA Prompt\n",
    "general_qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a compliance officer for general business regulations. Validate business suggestions for GDPR, CCPA, and FTC compliance, and refine them into technically actionable specifications.\\n\\n\"\n",
    "     \"‚úÖ Instructions:\\n\"\n",
    "     \"- For each suggestion:\\n\"\n",
    "     \"  * If fully compliant, refine it into a detailed technical specification.\\n\"\n",
    "     \"  * If not compliant, modify it to comply.\\n\"\n",
    "     \"  * Exclude suggestions that cannot be made compliant.\\n\\n\"\n",
    "     \"‚úÖ Output Format:\\n\"\n",
    "     \"- Provide a numbered list of refined, technically actionable suggestions.\\n\"\n",
    "     \"- Each must:\\n\"\n",
    "     \"    ‚Ä¢ Include technologies, frameworks, and implementation methods.\\n\"\n",
    "     \"    ‚Ä¢ Clearly describe how to ensure GDPR, CCPA, and FTC compliance.\\n\"\n",
    "     \"- Do not include introductions or explanations. Only output the refined suggestions.\\n\"\n",
    "    ),\n",
    "    (\"user\", \"{context}\\n\\nSuggestions to validate:\\n{suggestions}\")\n",
    "])\n",
    "\n",
    "general_qa_chain = LLMChain(llm=llm, prompt=general_qa_prompt)\n",
    "\n",
    "def run_general_qa(suggestions, retriever):\n",
    "    query = \"Does this comply with GDPR, CCPA, and FTC regulations?\"\n",
    "    relevant_docs = retriever.get_relevant_documents(query)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "\n",
    "    general_response = general_qa_chain.invoke({\"context\": context, \"suggestions\": suggestions})\n",
    "    return general_response[\"text\"].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Loading category: firebase\n",
      "\n",
      "üì• Loading category: gcp\n",
      "\n",
      "üì• Loading category: mongodb\n",
      "\n",
      "üì• Loading category: react_native\n",
      "\n",
      "üì• Loading category: ble_beacons\n",
      "\n",
      "üì• Loading category: pos_integration\n",
      "\n",
      "üß† Embedding and saving to vectorstore...\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# === STEP 1: All documentation URLs by category ===\n",
    "documentation_sources = {\n",
    "    \"firebase\": [\n",
    "        \"https://firebase.google.com/docs/auth\",\n",
    "        \"https://firebase.google.com/docs/firestore/security/get-started\",\n",
    "        \"https://firebase.google.com/docs/functions\",\n",
    "        \"https://firebase.google.com/docs/cloud-messaging\",\n",
    "        \"https://firebase.google.com/docs/emulator-suite\"\n",
    "    ],\n",
    "    \"gcp\": [\n",
    "        \"https://cloud.google.com/iam/docs/understanding-roles\",\n",
    "        \"https://cloud.google.com/iam/docs/service-accounts\",\n",
    "        \"https://cloud.google.com/resource-manager/docs/access-control-org\"\n",
    "    ],\n",
    "    \"mongodb\": [\n",
    "        \"https://www.mongodb.com/docs/manual/core/data-model-design/\",\n",
    "        \"https://www.mongodb.com/docs/manual/core/index-types/\",\n",
    "        \"https://www.mongodb.com/docs/manual/core/security-users/\",\n",
    "        \"https://www.mongodb.com/docs/manual/core/aggregation-pipeline/\",\n",
    "        \"https://www.mongodb.com/docs/manual/tutorial/manage-users/\"\n",
    "    ],\n",
    "    \"react_native\": [\n",
    "        \"https://docs.expo.dev/versions/latest/sdk/ble/\",\n",
    "        \"https://docs.expo.dev/versions/latest/sdk/camera/\",\n",
    "        \"https://docs.expo.dev/push-notifications/overview/\"\n",
    "    ],\n",
    "    \"ble_beacons\": [\n",
    "        \"https://developer.estimote.com/proximity/\",\n",
    "        \"https://developer.estimote.com/indoor/\",\n",
    "        \"https://developer.kontakt.io/\"\n",
    "    ],\n",
    "    \"pos_integration\": [\n",
    "        \"https://developer.shopify.com/docs/api\",\n",
    "        \"https://developer.squareup.com/reference/square\",\n",
    "        \"https://developer.vendhq.com/documentation/introduction\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# === STEP 2: Config ===\n",
    "PERSIST_DIR = \"./full_tech_vectorstore\"\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 200\n",
    "\n",
    "# === STEP 3: Load, Chunk, Embed, and Store ===\n",
    "def build_vectorstore(doc_sources):\n",
    "    all_chunks = []\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "    for category, urls in doc_sources.items():\n",
    "        print(f\"\\nüì• Loading category: {category}\")\n",
    "        try:\n",
    "            loader = WebBaseLoader(urls)\n",
    "            docs = loader.load()\n",
    "            for doc in docs:\n",
    "                doc.metadata[\"category\"] = category\n",
    "            chunks = splitter.split_documents(docs)\n",
    "            for chunk in chunks:\n",
    "                chunk.metadata[\"category\"] = category\n",
    "            all_chunks.extend(chunks)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error loading {category}: {e}\")\n",
    "\n",
    "    print(\"\\nüß† Embedding and saving to vectorstore...\")\n",
    "    tech_vectordb = FAISS.from_documents(all_chunks, embedding=embedding_model)\n",
    "    tech_vectordb.save_local(\"/Users/chandrimadas/Documents/agents_streamlit/vectorstores/tech_faiss_db\")\n",
    "\n",
    "    # vectordb = Chroma.from_documents(all_chunks, embedding=embedding_model, persist_directory=persist_dir)\n",
    "    # vectordb.persist()\n",
    "    # print(f\"\\n‚úÖ Vectorstore saved to {persist_dir}\")\n",
    "\n",
    "# === Run the builder ===\n",
    "if __name__ == \"__main__\":\n",
    "    # Path(PERSIST_DIR).mkdir(exist_ok=True)\n",
    "    build_vectorstore(documentation_sources)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "# from langchain.embeddings import GoogleGenerativeAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Load your tech vector store\n",
    "tech_vectordb = Chroma(persist_directory=\"/Users/chandrimadas/Documents/dual_agents/full_tech_vectorstore\", embedding_function=embedding_model)\n",
    "\n",
    "# Initialize Gemini model\n",
    "chat_model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "\n",
    "# Define technical agent prompt\n",
    "tech_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a technical solutions architect. Based on the provided business suggestions and technical documentation, provide detailed, step-by-step implementation strategies, tools, and best practices. Be specific and include architecture, services, and data considerations.\"),\n",
    "    (\"user\", \"{tech_context}\\n\\nBusiness Suggestions: {business_suggestions}\")\n",
    "])\n",
    "\n",
    "# Set up the LLM chain for the technical agent\n",
    "tech_llm_chain = LLMChain(llm=chat_model, prompt=tech_prompt)\n",
    "\n",
    "\n",
    "# Function to retrieve technical context\n",
    "def retrieve_tech_context(vectorstore, business_suggestions, k=3):\n",
    "    docs = vectorstore.similarity_search(business_suggestions, k=k)\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "\n",
    "# Complete technical agent pipeline\n",
    "def technical_agent_pipeline(business_suggestions):\n",
    "    # Retrieve the most relevant technical docs\n",
    "    tech_context = retrieve_tech_context(tech_vectordb, business_suggestions, k=3)\n",
    "    \n",
    "    # Get implementation strategies from Gemini\n",
    "    response = tech_llm_chain.run(tech_context=tech_context, business_suggestions=business_suggestions)\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technical Implementation Plan:\n",
      "\n",
      "## Implementation Strategy: Proactive Customer Support for Square\n",
      "\n",
      "This document outlines a step-by-step implementation strategy for proactive customer support, incorporating in-app help, HIPAA-compliant live chat, and secure logging.\n",
      "\n",
      "**I. Architecture:**\n",
      "\n",
      "The solution will utilize a microservices architecture to ensure scalability, maintainability, and flexibility. Key services include:\n",
      "\n",
      "* **In-App Help Center Service:**  This service will handle the delivery of FAQs, tutorials, and contextual help within the Square application.  It will leverage a content management system (CMS) for easy updates and version control.\n",
      "* **Live Chat Service:** This service will integrate with a HIPAA-compliant live chat platform (e.g.,  Talkdesk, Zendesk, or a custom solution built on a compliant platform like AWS HIPAA eligible services).  It will manage real-time chat sessions, agent routing, and chat history.\n",
      "* **Logging and Analytics Service:** This service will securely store all support interactions, including chat transcripts, user feedback, and help center usage data.  It will utilize a robust logging framework and a secure database (e.g.,  PostgreSQL with encryption at rest and in transit).  This data will be instrumental for identifying trends, improving support processes, and generating insightful analytics.\n",
      "* **User Authentication and Authorization Service:** This service will manage user authentication and authorization, ensuring only authorized personnel can access sensitive support data.  It will integrate with Square's existing authentication system.\n",
      "\n",
      "**II. Step-by-Step Implementation:**\n",
      "\n",
      "**Phase 1: In-App Help Center:**\n",
      "\n",
      "1. **Content Strategy:** Define the scope of FAQs and tutorials. Categorize content logically for easy navigation.\n",
      "2. **CMS Selection:** Choose a CMS (e.g.,  WordPress, Contentful, Strapi) that meets scalability and security requirements.  Consider headless CMS approaches for greater flexibility.\n",
      "3. **API Integration:** Develop APIs to integrate the CMS with the Square application.  This will allow dynamic content updates without requiring app store releases.\n",
      "4. **UI/UX Design:** Design an intuitive and user-friendly in-app help center interface.  Ensure seamless integration with the existing app design.\n",
      "5. **Development and Testing:** Develop and thoroughly test the in-app help center, including cross-browser and device compatibility testing.\n",
      "6. **Deployment:** Deploy the in-app help center to the Square application.\n",
      "\n",
      "**Phase 2: HIPAA-Compliant Live Chat Integration:**\n",
      "\n",
      "1. **Platform Selection:** Select a HIPAA-compliant live chat platform.  Conduct a thorough evaluation based on features, security, scalability, and pricing.  Consider factors like Business Associate Agreements (BAAs).\n",
      "2. **API Integration:** Integrate the chosen platform's API with the Square application and the Logging and Analytics Service.  This includes handling user authentication, chat session initiation, and message routing.\n",
      "3. **Agent Training:** Train support agents on the new platform and procedures.\n",
      "4. **Security Configuration:** Configure the live chat platform to meet HIPAA security requirements, including data encryption, access controls, and audit trails.\n",
      "5. **Testing and Deployment:** Thoroughly test the integration, including security testing and performance testing.  Deploy the live chat functionality to the Square application.\n",
      "\n",
      "**Phase 3: Logging and Analytics:**\n",
      "\n",
      "1. **Database Selection:** Choose a secure and scalable database (e.g., PostgreSQL with encryption) to store support interaction logs.\n",
      "2. **Logging Framework:** Implement a robust logging framework (e.g., ELK stack, Splunk) to capture all support interactions.\n",
      "3. **Data Security:** Implement appropriate security measures, including data encryption at rest and in transit, access controls, and regular security audits.  Ensure compliance with relevant data privacy regulations (HIPAA, GDPR, etc.).\n",
      "4. **Analytics Dashboard:** Develop an analytics dashboard to visualize support data, identify trends, and measure key performance indicators (KPIs).\n",
      "5. **Deployment and Monitoring:** Deploy the logging and analytics service and monitor its performance and security.\n",
      "\n",
      "**III. Tools and Technologies:**\n",
      "\n",
      "* **Programming Languages:** Java, Python, Node.js (depending on the chosen technologies for each service)\n",
      "* **Databases:** PostgreSQL, MySQL (with encryption)\n",
      "* **Cloud Platforms:** AWS (with HIPAA eligible services), Azure, Google Cloud Platform (GCP)\n",
      "* **CMS:** WordPress, Contentful, Strapi\n",
      "* **Live Chat Platforms:** Talkdesk, Zendesk, Intercom (ensure HIPAA compliance)\n",
      "* **Logging and Analytics:** ELK stack, Splunk, Datadog\n",
      "* **API Gateways:** Kong, Apigee\n",
      "* **CI/CD:** Jenkins, GitLab CI, CircleCI\n",
      "\n",
      "\n",
      "**IV. Data Considerations:**\n",
      "\n",
      "* **Data Encryption:** Encrypt all sensitive data both at rest and in transit.\n",
      "* **Access Control:** Implement role-based access control (RBAC) to restrict access to sensitive data.\n",
      "* **Data Retention:** Establish a data retention policy that complies with relevant regulations.\n",
      "* **Data Backup and Recovery:** Implement a robust data backup and recovery plan.\n",
      "* **HIPAA Compliance:** Ensure all data handling practices comply with HIPAA regulations, including BAAs with vendors.\n",
      "\n",
      "**V. Best Practices:**\n",
      "\n",
      "* **Agile Development:** Utilize agile methodologies for iterative development and faster feedback loops.\n",
      "* **Automated Testing:** Implement comprehensive automated testing to ensure quality and reliability.\n",
      "* **Security Audits:** Conduct regular security audits to identify and address vulnerabilities.\n",
      "* **Monitoring and Alerting:** Implement monitoring and alerting to proactively identify and resolve issues.\n",
      "* **Documentation:** Maintain comprehensive documentation for all aspects of the system.\n",
      "\n",
      "\n",
      "This comprehensive plan provides a structured approach to implementing proactive customer support for Square, prioritizing security, scalability, and user experience.  Remember to adapt this plan based on Square's specific needs and existing infrastructure.  Prioritizing security and compliance with HIPAA is paramount throughout the entire process.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example validated suggestions from QA agent\n",
    "    validated_suggestions = \"\"\"\n",
    "    \n",
    "    1. Implement an intuitive, voice-assisted mobile app to support elderly patients.\n",
    "    2. Integrate real-time appointment reminders via SMS and automated calls.\n",
    "    # 3. Ensure HIPAA-compliant cloud storage for patient data and records.\n",
    "    \"\"\"\n",
    "\n",
    "    technical_solution = technical_agent_pipeline(qa_result)\n",
    "    print(\"Technical Implementation Plan:\\n\")\n",
    "    print(technical_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Categorization prompt for the entire suggestion block\n",
    "categorization_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a classification engine. Categorize the entire set of business suggestions into one of the following domains:\\n\\n\"\n",
    "     \"- Healthcare\\n- Education\\n- General\\n\\n\"\n",
    "     \"‚úÖ Instructions:\\n\"\n",
    "     \"Analyze the suggestions and return only one category name based on the primary focus.\\n\\n\"\n",
    "     \"‚úÖ Output Format:\\n\"\n",
    "     \"Healthcare\\nOR\\nEducation\\nOR\\nGeneral\"),\n",
    "    (\"user\", \"Business Suggestions:\\n{suggestions}\")\n",
    "])\n",
    "\n",
    "categorization_chain = LLMChain(llm=llm, prompt=categorization_prompt)\n",
    "\n",
    "def categorize_suggestions(suggestions):\n",
    "    result = categorization_chain.invoke({\"suggestions\": suggestions})\n",
    "    return result['text'].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_suggestions(suggestions, retrievers):\n",
    "    category = categorize_suggestions(suggestions)\n",
    "\n",
    "    if category == \"Healthcare\":\n",
    "        result = run_healthcare_qa(suggestions, retrievers['healthcare'])\n",
    "    elif category == \"Education\":\n",
    "        result = run_education_qa(suggestions, retrievers['education'])\n",
    "    elif category == \"General\":\n",
    "        result = run_general_qa(suggestions, retrievers['general'])\n",
    "    else:\n",
    "        result = \"‚ùå Could not determine category. Please review suggestions.\"\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Categorized & QA Agent Feedback:\n",
      "\n",
      "1. **Tiered Subscription Model with Value-Added Services:**\n",
      "\n",
      "* **Technology:**  Develop a microservices architecture using Node.js/Express.js for backend APIs and React Native for cross-platform mobile app development.  Implement a robust payment gateway integration (e.g., Stripe, Braintree) adhering to PCI DSS standards.  Utilize a cloud-based database (e.g., AWS RDS, Google Cloud SQL) with encryption at rest and in transit (AES-256).\n",
      "* **Compliance:**  All data transmission will be encrypted using TLS 1.3 or higher.  HIPAA compliance will be achieved through adherence to the Security Rule, including access controls, audit trails, and data integrity mechanisms.  PHI will be stored and processed according to HIPAA regulations.  Telehealth consultations will comply with relevant state and federal regulations.\n",
      "* **Implementation:**  Develop three subscription tiers: Basic (free, core features), Premium (paid, telehealth consultations, personalized health coaching), and Enterprise (paid, advanced analytics, medication management).  Each tier will have clearly defined features and pricing.  Implement robust user authentication and authorization mechanisms using OAuth 2.0 and JWT.\n",
      "\n",
      "\n",
      "2. **Automated Processes and EHR Integration:**\n",
      "\n",
      "* **Technology:**  Utilize HL7 FHIR APIs for seamless integration with existing EHR systems.  Implement a message queue (e.g., RabbitMQ, Kafka) for asynchronous communication between the app and EHR systems.  Employ serverless functions (e.g., AWS Lambda, Google Cloud Functions) for automated tasks like appointment scheduling, lab result notifications, and appointment reminders.\n",
      "* **Compliance:**  All data exchanged with EHR systems will be encrypted using TLS 1.3 or higher and authenticated using appropriate security protocols.  Data integrity will be ensured through checksums and digital signatures.  Access controls will be implemented to restrict access to PHI based on roles and responsibilities.  Audit trails will be maintained to track all data access and modifications.  Compliance with HIPAA, FDA, and HHS regulations will be ensured through rigorous testing and validation.\n",
      "* **Implementation:**  Develop FHIR-compliant APIs for appointment scheduling, lab result retrieval, and patient communication.  Implement automated workflows for appointment reminders, lab result notifications, and medication refill requests.  Utilize a robust error handling and logging mechanism to ensure data integrity and system reliability.\n",
      "\n",
      "\n",
      "3. **Personalized User Experience and Proactive Support:**\n",
      "\n",
      "* **Technology:**  Implement a personalized dashboard using React Native, leveraging user data and preferences to display relevant information.  Integrate a chatbot using Dialogflow or similar technology for in-app customer support.  Utilize machine learning algorithms to identify potential health risks and send proactive alerts.  Implement a feedback mechanism using a survey tool (e.g., SurveyMonkey, Qualtrics).\n",
      "* **Compliance:**  All user data will be handled according to HIPAA regulations.  The chatbot will be designed to avoid providing medical advice and will direct users to appropriate healthcare professionals when necessary.  Proactive health alerts will be based on evidence-based guidelines and will not constitute medical advice.  Feedback data will be anonymized and aggregated to protect user privacy.\n",
      "* **Implementation:**  Develop a personalized dashboard that dynamically adapts to user preferences and health data.  Integrate a chatbot with a knowledge base of FAQs and troubleshooting guides.  Develop algorithms to identify potential health risks based on user data and send timely alerts.  Implement a user feedback mechanism to collect and analyze user feedback for continuous improvement.\n",
      "\n",
      "üõ†Ô∏è Technical Implementation Plan:\n",
      "\n",
      "## Implementation Strategies for Healthcare App\n",
      "\n",
      "This document outlines detailed implementation strategies for the three business suggestions, incorporating security, compliance, and scalability best practices.\n",
      "\n",
      "**I. Tiered Subscription Model with Value-Added Services**\n",
      "\n",
      "**A. Architecture:**\n",
      "\n",
      "1. **Frontend:** React Native for cross-platform mobile app development.  This allows for code reusability and faster development across iOS and Android.\n",
      "2. **Backend:** Microservices architecture using Node.js/Express.js. This provides flexibility, scalability, and maintainability.  Individual services will handle user accounts, subscriptions, payments, and telehealth consultations.\n",
      "3. **Database:**  Google Cloud SQL (PostgreSQL or MySQL) for relational data management, offering scalability, security (encryption at rest and in transit with AES-256), and compliance features.  Consider using separate databases for different services to enhance security and isolate data.\n",
      "4. **Payment Gateway:** Integrate Stripe or Braintree, adhering strictly to PCI DSS standards.  This includes secure handling of credit card information, regular security audits, and compliance with data security requirements.\n",
      "5. **API Gateway:**  Implement an API gateway (e.g., Kong, Apigee) to manage API requests, enforce security policies (authentication, authorization), and provide load balancing.\n",
      "\n",
      "**B. Step-by-Step Implementation:**\n",
      "\n",
      "1. **Microservice Design:** Define individual microservices (e.g., User Service, Subscription Service, Payment Service, Telehealth Service).  Each service will have its own database schema and API endpoints.\n",
      "2. **Authentication and Authorization:** Implement OAuth 2.0 with JWT for secure user authentication and authorization.  This will control access to features based on subscription tiers.\n",
      "3. **Subscription Management:** Develop APIs to manage subscription plans, upgrades, downgrades, and cancellations.  Integrate with the chosen payment gateway.\n",
      "4. **Payment Processing:** Securely integrate with the payment gateway, ensuring PCI DSS compliance.  Implement robust error handling and logging for transaction failures.\n",
      "5. **Telehealth Integration (Premium/Enterprise):** Integrate a video conferencing platform (e.g., Twilio Video, Zoom) for secure telehealth consultations.  Ensure HIPAA compliance through encryption and access controls.\n",
      "6. **React Native Development:** Develop the mobile app UI, integrating with the backend APIs.  Implement user-friendly interfaces for managing subscriptions and accessing features.\n",
      "7. **Testing and Deployment:** Conduct thorough testing, including unit, integration, and end-to-end testing.  Deploy the application using a CI/CD pipeline for continuous integration and deployment.\n",
      "\n",
      "\n",
      "**II. Automated Processes and EHR Integration**\n",
      "\n",
      "**A. Architecture:**\n",
      "\n",
      "1. **FHIR API Server:**  Develop a FHIR-compliant API server to handle communication with EHR systems.  This will act as a bridge between the application and the EHRs.\n",
      "2. **Message Queue:**  Implement RabbitMQ or Kafka for asynchronous communication.  This ensures that the application remains responsive even during high loads.\n",
      "3. **Serverless Functions (Google Cloud Functions):** Utilize serverless functions for automated tasks (appointment scheduling, reminders, lab result notifications).  These functions will be triggered by events from the message queue or other sources.\n",
      "4. **Data Storage:**  Store processed data from EHR systems in Google Cloud SQL, ensuring HIPAA compliance and data integrity.\n",
      "\n",
      "**B. Step-by-Step Implementation:**\n",
      "\n",
      "1. **FHIR API Implementation:** Develop APIs to interact with the HL7 FHIR standard.  This requires understanding FHIR resources and operations.\n",
      "2. **Message Queue Configuration:** Set up RabbitMQ or Kafka, configuring queues and exchanges for different message types.\n",
      "3. **Serverless Function Development:** Develop serverless functions to handle automated tasks.  These functions should be highly reliable and fault-tolerant.\n",
      "4. **EHR Integration:** Establish secure connections with EHR systems using appropriate security protocols (TLS 1.3, mutual authentication).\n",
      "5. **Data Transformation and Mapping:** Implement data transformation logic to map data from EHR systems to the application's data model.\n",
      "6. **Error Handling and Logging:** Implement robust error handling and logging to track issues and ensure data integrity.\n",
      "7. **Security and Compliance:** Implement encryption, access controls, audit trails, and other security measures to comply with HIPAA, FDA, and HHS regulations.\n",
      "\n",
      "\n",
      "**III. Personalized User Experience and Proactive Support**\n",
      "\n",
      "**A. Architecture:**\n",
      "\n",
      "1. **Personalized Dashboard (React Native):** Develop a dynamic dashboard that adapts to user data and preferences.\n",
      "2. **Chatbot (Dialogflow):** Integrate a chatbot using Dialogflow or a similar platform.  This will provide in-app support and answer frequently asked questions.\n",
      "3. **Machine Learning (Google Cloud AI Platform):** Utilize machine learning algorithms (e.g., risk prediction models) to identify potential health risks.\n",
      "4. **Data Storage:**  Store user data and preferences in Google Cloud SQL, ensuring data privacy and security.\n",
      "\n",
      "**B. Step-by-Step Implementation:**\n",
      "\n",
      "1. **Dashboard Development:** Develop the personalized dashboard using React Native, integrating with backend APIs to fetch user data and preferences.\n",
      "2. **Chatbot Integration:** Integrate Dialogflow, training the chatbot with relevant FAQs and troubleshooting information.  Ensure that the chatbot does not provide medical advice.\n",
      "3. **Machine Learning Model Development:** Develop and train machine learning models to predict potential health risks based on user data.  Deploy these models to the Google Cloud AI Platform.\n",
      "4. **Proactive Alert System:** Implement a system to send timely alerts to users based on the predictions from the machine learning models.\n",
      "5. **User Feedback Mechanism:** Integrate a feedback mechanism (e.g., using a survey tool) to collect user feedback for continuous improvement.  Anonymize and aggregate feedback data to protect user privacy.\n",
      "\n",
      "\n",
      "**Overall Considerations:**\n",
      "\n",
      "* **Security:** Implement robust security measures throughout the application, including encryption, access controls, authentication, authorization, and regular security audits.\n",
      "* **Compliance:**  Ensure compliance with HIPAA, FDA, and HHS regulations, as well as any relevant state and federal regulations.\n",
      "* **Scalability:** Design the architecture to be scalable to handle increasing user traffic and data volume.\n",
      "* **Monitoring and Logging:** Implement comprehensive monitoring and logging to track application performance, identify issues, and ensure system reliability.\n",
      "* **Data Governance:** Establish clear data governance policies to manage data access, security, and privacy.\n",
      "\n",
      "\n",
      "This detailed implementation plan provides a strong foundation for building a secure, scalable, and compliant healthcare application.  Remember to continuously monitor and adapt the system to meet evolving business needs and regulatory requirements.  Regular security assessments and penetration testing are crucial for maintaining a robust security posture.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    retrievers = {\n",
    "        \"healthcare\": qa_retriever,\n",
    "        \"education\": edu_qa_retriever,  # Pre-built similar to qa_retriever but trained on FERPA, COPPA, ADA\n",
    "        \"general\": general_qa_retriever  # Pre-built similar to qa_retriever but trained on GDPR, CCPA, FTC\n",
    "    }\n",
    "\n",
    "    validated_suggestions = \"\"\"\n",
    "    1. Implement an intuitive, voice-assisted mobile app to support elderly patients.\n",
    "    2. Integrate student behavior tracking dashboards in K-12 educational apps.\n",
    "    3. Set up a global user tracking system for personalized e-commerce recommendations.\n",
    "    \"\"\"\n",
    "\n",
    "    qa_result = route_suggestions(suggestions, retrievers)\n",
    "\n",
    "    print(\"\\n‚úÖ Categorized & QA Agent Feedback:\\n\")\n",
    "    print(qa_result)\n",
    "\n",
    "    technical_solution = technical_agent_pipeline(qa_result)\n",
    "    print(\"\\nüõ†Ô∏è Technical Implementation Plan:\\n\")\n",
    "    print(technical_solution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(qa_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a business consultant. Analyze the provided documents and generate 3 actionable, section-referenced suggestions to improve the business model. Focus on revenue, operational efficiency, and customer satisfaction.\"),\n",
    "    (\"user\", \"{context}\\n\\n{question}\")\n",
    "])\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Load and split the PDF document\n",
    "def load_and_split_pdf(file_path):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    documents = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    return chunks\n",
    "\n",
    "# Process JSON dataset into Document chunks\n",
    "def process_json_dataset(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    documents = []\n",
    "    for entry in data:\n",
    "        documents.append(Document(page_content=f\"Brief: {entry['brief']}\\nSuggestions: {entry['suggestions']}\"))\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    return chunks\n",
    "\n",
    "# Build FAISS vectorstore\n",
    "def build_vectorstore(documents):\n",
    "    return FAISS.from_documents(documents, embedding_model)\n",
    "\n",
    "# Combined retrieval from both sources\n",
    "def retrieve_combined_context(pdf_vectorstore, json_vectorstore, query, k=2):\n",
    "    pdf_docs = pdf_vectorstore.similarity_search(query, k=k)\n",
    "    json_docs = json_vectorstore.similarity_search(query, k=k)\n",
    "\n",
    "    combined_context = \"\\n\\n\".join([doc.page_content for doc in pdf_docs + json_docs])\n",
    "    return combined_context\n",
    "\n",
    "# Business agent pipeline\n",
    "def business_agent_pipeline(client_pdf_path, client_query, json_dataset_path):\n",
    "    # Process client PDF\n",
    "    pdf_chunks = load_and_split_pdf(client_pdf_path)\n",
    "    pdf_vectorstore = build_vectorstore(pdf_chunks)\n",
    "\n",
    "    # Process JSON dataset\n",
    "    json_chunks = process_json_dataset(json_dataset_path)\n",
    "    json_vectorstore = build_vectorstore(json_chunks)\n",
    "\n",
    "    # Retrieve context\n",
    "    context = retrieve_combined_context(pdf_vectorstore, json_vectorstore, client_query, k=2)\n",
    "\n",
    "    # Run the LLM chain\n",
    "    response = chain.invoke({\"context\": context, \"question\": client_query})\n",
    "    return response[\"text\"]\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    client_pdf_path = \"/Users/chandrimadas/Documents/dual_agents/sample_brief.pdf\"\n",
    "    json_dataset_path = \"/Users/chandrimadas/Documents/dual_agents/business_agent_dataset_detailed.json\"\n",
    "    client_query = \"Suggest a way to enhance patient satisfaction and retention in a healthcare mobile app, considering secure data handling and remote access features.\"\n",
    "\n",
    "    suggestions = business_agent_pipeline(client_pdf_path, client_query, json_dataset_path)\n",
    "    print(\"\\nüîç Business Agent Suggestions:\\n\")\n",
    "    print(suggestions)\n",
    "    \n",
    "#HEALTH QA\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "urls = [\n",
    "    \"https://www.hhs.gov/hipaa/for-professionals/privacy/index.html\",\n",
    "    \"https://www.fda.gov/regulatory-information/search-fda-guidance-documents/mobile-medical-applications\",\n",
    "    \"https://www.hhs.gov/ash/patient-safety/index.html\"\n",
    "]\n",
    "\n",
    "# Load web pages directly\n",
    "loaders = [WebBaseLoader(url) for url in urls]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "qa_vectordb = Chroma.from_documents(chunks, embedding=embedding_model, persist_directory=\"./qa_chroma_db\")\n",
    "\n",
    "qa_retriever = qa_vectordb.as_retriever(search_kwargs={\"k\": 5})\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a healthcare compliance officer and technical specification preparer. Your task is to validate business suggestions for compliance with HIPAA, FDA, and HHS regulations and refine them into technically actionable specifications.\\n\\n\"\n",
    "     \n",
    "     \"‚úÖ Instructions:\\n\"\n",
    "     \"- For each suggestion:\\n\"\n",
    "     \"  * If fully compliant, refine it into a detailed technical specification.\\n\"\n",
    "     \"  * If not compliant, modify it to comply.\\n\"\n",
    "     \"  * Exclude suggestions that cannot be made compliant.\\n\\n\"\n",
    "     \n",
    "     \"‚úÖ Output Format:\\n\"\n",
    "     \"- Provide a numbered list of refined, technically actionable suggestions.\\n\"\n",
    "     \"- Each suggestion must:\\n\"\n",
    "     \"    ‚Ä¢ Include specific technologies, frameworks, or implementation methods.\\n\"\n",
    "     \"    ‚Ä¢ Clearly describe how to ensure regulatory compliance (e.g., encryption standard, API security protocol).\\n\"\n",
    "    #  \"    ‚Ä¢ Include regulatory tags at the end like [HIPAA], [FDA], [HHS].\\n\"\n",
    "     \"    ‚Ä¢ Be written clearly enough for a technical team to immediately start system design or development.\\n\"\n",
    "     \"- Do not include introductions or explanations. Only output the refined suggestions.\\n\"\n",
    "    ),\n",
    "    (\"user\", \"{context}\\n\\nSuggestions to validate:\\n{suggestions}\")\n",
    "])\n",
    "\n",
    "qa_chain = LLMChain(llm=llm, prompt=qa_prompt)\n",
    "\n",
    "def run_healthcare_qa(suggestions, retriever):\n",
    "    query = \"Does this comply with HIPAA, FDA, and HHS guidelines?\"\n",
    "    relevant_docs = retriever.get_relevant_documents(query)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "\n",
    "    qa_response = qa_chain.invoke({\"context\": context, \"suggestions\": suggestions})\n",
    "    return qa_response[\"text\"].strip()\n",
    "qa_result = run_healthcare_qa(suggestions, qa_retriever)\n",
    "\n",
    "print(\"\\n‚úÖ QA Agent Feedback:\\n\")\n",
    "print(qa_result)\n",
    "\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# URLs for Education Compliance\n",
    "edu_urls = [\n",
    "    \"https://studentprivacy.ed.gov/\",\n",
    "    \"https://www.ftc.gov/business-guidance/privacy-security/childrens-privacy\",\n",
    "    \"https://www.ada.gov/resources/overview/\"\n",
    "]\n",
    "\n",
    "# Load web pages\n",
    "edu_loaders = [WebBaseLoader(url) for url in edu_urls]\n",
    "edu_docs = []\n",
    "for loader in edu_loaders:\n",
    "    edu_docs.extend(loader.load())\n",
    "\n",
    "# Split documents\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)\n",
    "edu_chunks = splitter.split_documents(edu_docs)\n",
    "\n",
    "# Initialize embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Build Education Vector DB\n",
    "edu_qa_vectordb = Chroma.from_documents(edu_chunks, embedding=embedding_model, persist_directory=\"./edu_qa_chroma_db\")\n",
    "\n",
    "# Build Retriever\n",
    "edu_qa_retriever = edu_qa_vectordb.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# Education QA Prompt\n",
    "edu_qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are an education compliance officer and technical specification preparer. Validate business suggestions for FERPA, COPPA, and ADA compliance, and refine them into technically actionable specifications.\\n\\n\"\n",
    "     \"‚úÖ Instructions:\\n\"\n",
    "     \"- For each suggestion:\\n\"\n",
    "     \"  * If fully compliant, refine it into a detailed technical specification.\\n\"\n",
    "     \"  * If not compliant, modify it to comply.\\n\"\n",
    "     \"  * Exclude suggestions that cannot be made compliant.\\n\\n\"\n",
    "     \"‚úÖ Output Format:\\n\"\n",
    "     \"- Provide a numbered list of refined, technically actionable suggestions.\\n\"\n",
    "     \"- Each must:\\n\"\n",
    "     \"    ‚Ä¢ Include technologies, frameworks, and implementation methods.\\n\"\n",
    "     \"    ‚Ä¢ Clearly describe how to ensure FERPA, COPPA, and ADA compliance.\\n\"\n",
    "     \"- Do not include introductions or explanations. Only output the refined suggestions.\\n\"\n",
    "    ),\n",
    "    (\"user\", \"{context}\\n\\nSuggestions to validate:\\n{suggestions}\")\n",
    "])\n",
    "\n",
    "edu_qa_chain = LLMChain(llm=llm, prompt=edu_qa_prompt)\n",
    "\n",
    "def run_education_qa(suggestions, retriever):\n",
    "    query = \"Does this comply with FERPA, COPPA, and ADA regulations?\"\n",
    "    relevant_docs = retriever.get_relevant_documents(query)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "\n",
    "    edu_response = edu_qa_chain.invoke({\"context\": context, \"suggestions\": suggestions})\n",
    "    return edu_response[\"text\"].strip()\n",
    "\n",
    "# URLs for General Compliance\n",
    "general_urls = [\n",
    "    \"https://gdpr-info.eu/\",\n",
    "    \"https://oag.ca.gov/privacy/ccpa\",\n",
    "    \"https://www.ftc.gov/business-guidance/privacy-security\"\n",
    "]\n",
    "\n",
    "# Load web pages\n",
    "general_loaders = [WebBaseLoader(url) for url in general_urls]\n",
    "general_docs = []\n",
    "for loader in general_loaders:\n",
    "    general_docs.extend(loader.load())\n",
    "\n",
    "# Split documents\n",
    "general_chunks = splitter.split_documents(general_docs)\n",
    "\n",
    "# Build General Vector DB\n",
    "general_qa_vectordb = Chroma.from_documents(general_chunks, embedding=embedding_model, persist_directory=\"./general_qa_chroma_db\")\n",
    "\n",
    "# Build Retriever\n",
    "general_qa_retriever = general_qa_vectordb.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# General QA Prompt\n",
    "general_qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a compliance officer for general business regulations. Validate business suggestions for GDPR, CCPA, and FTC compliance, and refine them into technically actionable specifications.\\n\\n\"\n",
    "     \"‚úÖ Instructions:\\n\"\n",
    "     \"- For each suggestion:\\n\"\n",
    "     \"  * If fully compliant, refine it into a detailed technical specification.\\n\"\n",
    "     \"  * If not compliant, modify it to comply.\\n\"\n",
    "     \"  * Exclude suggestions that cannot be made compliant.\\n\\n\"\n",
    "     \"‚úÖ Output Format:\\n\"\n",
    "     \"- Provide a numbered list of refined, technically actionable suggestions.\\n\"\n",
    "     \"- Each must:\\n\"\n",
    "     \"    ‚Ä¢ Include technologies, frameworks, and implementation methods.\\n\"\n",
    "     \"    ‚Ä¢ Clearly describe how to ensure GDPR, CCPA, and FTC compliance.\\n\"\n",
    "     \"- Do not include introductions or explanations. Only output the refined suggestions.\\n\"\n",
    "    ),\n",
    "    (\"user\", \"{context}\\n\\nSuggestions to validate:\\n{suggestions}\")\n",
    "])\n",
    "\n",
    "general_qa_chain = LLMChain(llm=llm, prompt=general_qa_prompt)\n",
    "\n",
    "def run_general_qa(suggestions, retriever):\n",
    "    query = \"Does this comply with GDPR, CCPA, and FTC regulations?\"\n",
    "    relevant_docs = retriever.get_relevant_documents(query)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "\n",
    "    general_response = general_qa_chain.invoke({\"context\": context, \"suggestions\": suggestions})\n",
    "    return general_response[\"text\"].strip()\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "# from langchain.embeddings import GoogleGenerativeAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Load your tech vector store\n",
    "tech_vectordb = Chroma(persist_directory=\"/Users/chandrimadas/Documents/dual_agents/full_tech_vectorstore\", embedding_function=embedding_model)\n",
    "\n",
    "# Initialize Gemini model\n",
    "chat_model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "\n",
    "# Define technical agent prompt\n",
    "tech_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a technical solutions architect. Based on the provided business suggestions and technical documentation, provide detailed, step-by-step implementation strategies, tools, and best practices. Be specific and include architecture, services, and data considerations.\"),\n",
    "    (\"user\", \"{tech_context}\\n\\nBusiness Suggestions: {business_suggestions}\")\n",
    "])\n",
    "\n",
    "# Set up the LLM chain for the technical agent\n",
    "tech_llm_chain = LLMChain(llm=chat_model, prompt=tech_prompt)\n",
    "\n",
    "\n",
    "# Function to retrieve technical context\n",
    "def retrieve_tech_context(vectorstore, business_suggestions, k=3):\n",
    "    docs = vectorstore.similarity_search(business_suggestions, k=k)\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "\n",
    "# Complete technical agent pipeline\n",
    "def technical_agent_pipeline(business_suggestions):\n",
    "    # Retrieve the most relevant technical docs\n",
    "    tech_context = retrieve_tech_context(tech_vectordb, business_suggestions, k=3)\n",
    "    \n",
    "    # Get implementation strategies from Gemini\n",
    "    response = tech_llm_chain.run(tech_context=tech_context, business_suggestions=business_suggestions)\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Categorization prompt for the entire suggestion block\n",
    "categorization_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a classification engine. Categorize the entire set of business suggestions into one of the following domains:\\n\\n\"\n",
    "     \"- Healthcare\\n- Education\\n- General\\n\\n\"\n",
    "     \"‚úÖ Instructions:\\n\"\n",
    "     \"Analyze the suggestions and return only one category name based on the primary focus.\\n\\n\"\n",
    "     \"‚úÖ Output Format:\\n\"\n",
    "     \"Healthcare\\nOR\\nEducation\\nOR\\nGeneral\"),\n",
    "    (\"user\", \"Business Suggestions:\\n{suggestions}\")\n",
    "])\n",
    "\n",
    "categorization_chain = LLMChain(llm=llm, prompt=categorization_prompt)\n",
    "\n",
    "def categorize_suggestions(suggestions):\n",
    "    result = categorization_chain.invoke({\"suggestions\": suggestions})\n",
    "    return result['text'].strip()\n",
    "\n",
    "def route_suggestions(suggestions, retrievers):\n",
    "    category = categorize_suggestions(suggestions)\n",
    "\n",
    "    if category == \"Healthcare\":\n",
    "        result = run_healthcare_qa(suggestions, retrievers['healthcare'])\n",
    "    elif category == \"Education\":\n",
    "        result = run_education_qa(suggestions, retrievers['education'])\n",
    "    elif category == \"General\":\n",
    "        result = run_general_qa(suggestions, retrievers['general'])\n",
    "    else:\n",
    "        result = \"‚ùå Could not determine category. Please review suggestions.\"\n",
    "\n",
    "    return result\n",
    "if __name__ == \"__main__\":\n",
    "    retrievers = {\n",
    "        \"healthcare\": qa_retriever,\n",
    "        \"education\": edu_qa_retriever,  # Pre-built similar to qa_retriever but trained on FERPA, COPPA, ADA\n",
    "        \"general\": general_qa_retriever  # Pre-built similar to qa_retriever but trained on GDPR, CCPA, FTC\n",
    "    }\n",
    "\n",
    "    validated_suggestions = \"\"\"\n",
    "    1. Implement an intuitive, voice-assisted mobile app to support elderly patients.\n",
    "    2. Integrate student behavior tracking dashboards in K-12 educational apps.\n",
    "    3. Set up a global user tracking system for personalized e-commerce recommendations.\n",
    "    \"\"\"\n",
    "\n",
    "    qa_result = route_suggestions(suggestions, retrievers)\n",
    "\n",
    "    print(\"\\n‚úÖ Categorized & QA Agent Feedback:\\n\")\n",
    "    print(qa_result)\n",
    "\n",
    "    technical_solution = technical_agent_pipeline(qa_result)\n",
    "    print(\"\\nüõ†Ô∏è Technical Implementation Plan:\\n\")\n",
    "    print(technical_solution)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
